\documentclass[12pt]{amsart}
\usepackage[utf8]{inputenc}
\usepackage[
backend=biber,
style=numeric,
maxbibnames=99,
sorting=ynt
]{biblatex}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{tikz}
\usepackage{standalone}
\usepackage{svg}
\usepackage{gensymb}
\usepackage{float}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx, animate}
\usepackage{caption, subcaption}
\usepackage{pgffor}
\usepackage{mathtools}
\usepackage{array}
\addbibresource{bibliography.bib}
\usepackage{hyperref,thmtools}
\linespread{1.5}

% Override ugly default link
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = blue    %Colour of citations
}



\begin{document}    
\section{Plan}
    \subsection{Catalyst (Intro)}
        Temporal networks pop up everywhere and would be really nice if we could model them.

    \subsection{What methods are out there}
        Exploration of whats there for temporal network modelling and what challenges they have faced
    
    \subsection{Proposition for using DE (and problems that arise from this approach)}

    \subsection{UDEs (we may not have much knowledge of the system so may use UDEs)}
        Exploration of its uses and limitations
        (Hopefully find some stuff about them being black boxes)

    \subsection{Symbolic regression (Illustrate that it has been well researched and shown positive results)}

\section{Questions}
    Worth having definitions in appendices

\begin{section}{Literature Review}

    \subsection{Temporal Networks}
        Temporal networks are used to describe a series of interactions across time; an example of this can be found in XXX ref temp net example XXX. This can be represented in many ways, for example as a series of interactions or as series of adjacency matrices ordered by time. The series of interactions is generally represented as a list of tuples containing the node that interacted and the time that the interaction took place. In the representation of a series of adjacency matrices, the columns and rows of the matrix each refer to each of the nodes. In this way, if an edge exists between nodes $i$ and $j$, the entry $(i,j)$ of the adjacency matrix will be 1; if an edge does not exist the entry will be 0.

        Temporal networks are present in many areas of research interest, ranging from symptom interactions in mental health\cite{jordan2020current,contreras2020temporal}, to epidemiology\cite{masuda2013predicting}, protein interactions\cite{lucas2021inferring,jin2009identifying}, and social networks\cite{moinet2015burstiness,hanneke2010discrete}.     
        
        Generally attempts to model temporal networks either model the change in node state, that is, some information about that node; for example the severity of a symptom at a given time, as in \cite{contreras2020temporal}. Or they model the changing structure of the network as in \cite{sanna2021link}. 

        \Citeauthor{contreras2020temporal} \cite{contreras2020temporal} model the change in node state over time while the structure of the network remains constant. \Citeauthor{contreras2020temporal} look at the severity of symptoms over time, i.e. the state of the nodes, as a temporal network where the network structure remains constant. They use multilevel vector autoregression, a method that finds correlations between the current state of a variable and the states of variables at previous time steps \cite{singer2003applied}, to model how the current symptoms of people with paranoia might predict their future symptoms. These models were then used to create three networks that linked symptoms. Of particular interest to this thesis is the temporal network created by having a fully connected network of all symptoms including self-loops, where a symptom connects to itself; this self loop comes about from a symptom being correlated with itself from one time step to the next. The edge weights represent the extent to which the severity of each symptom at time $(t)$ predicts the severity of itself and other symptoms at time $(t+1)$. This framework keeps the overall structure of the network fixed throughout time and so is not particularly flexible, but is extremely human interpretable and can be used to extrapolate and predict into the future. 

        In \cite{KARIMI20133476}, the \Citeauthor{KARIMI20133476} look to model the change in node state while the network structure changes. \Citeauthor{KARIMI20133476} represent their temporal network as a series of interactions (a list of tuples in the form $(i,j,t)$, where $i,j$ are the nodes interacting and $t$ is the time the at which the interaction occurred). The authors use a model to predict when a node will change from state 0 to state 1, in practice this could represent whether a user of a social network believes a rumour, or an ecological patch being colonised. Notably, in their model the node never changes back; this is done to keep the model analytically tractable, but does limit its usefulness in some contexts. In this model an organism could not become locally extinct in an ecological patch for example. To model the change in a nodes' state, the model uses a sliding time window and if the fraction of interactions with nodes of state 1 within that time window exceeds a given threshold, the node switches to state 1 as well. 

        This paper does not aim to present a model for predicting the state of a node in the future. Instead, it aims to present a tool for understanding the spread of ideas, viruses, etc. within a network.


        Pasino et al.\cite{sanna2021link} model the change in the structure of a temporal network. In this case the \Citeauthor{sanna2021link} represent the temporal network as a series of adjacency matrices, each matrix representing an observation of the changing network. The authors look to model the structure of edges by using a spectral embedding (SVD). A spectral embedding uses the eigenvectors of a network's adjacency matrix to find vectors that represent the nodes of the network. The spectral embedding transforms their temporal sequence into a sequence of observations of a latent space. A latent space is a continuous space in which similar nodes (nodes with many of the same neighbours) are positioned near each other. In this space nodes are represented as points in a continuous, low dimensional space. Another feature of this latent space, is that the dot product of any two points in the space gives us the probability that the nodes related to those points are connected.  With this series of embeddings, the authors employ a variety of time series techniques to predict the network structure at future time steps.

    \subsection{UDEs and NNDEs}
        In some temporal networks the state of a node might influence the evolution of its neighbours. For example, in social networks we often observe the power law distribution of edges, where the more neighbours a node has, the more likely they are to gain more neighbours\cite{zhao2012multi,garg2009evolution}. We also see that the state of symptoms (occurrence, severity, and distress), can influence the states of other symptoms in patients undergoing chemotherapy \cite{papachristou2019network,kalantari2022network}, and for mental health disorders \cite{contreras2020temporal}. As well as in ecological networks where the interactions of species are often represented as a network, and the populations of one species may influence the population growth of another \cite{elton2001animal,volterra1927variazioni}; that is, the state (in this case the population) of a species (node), may influence the movement of another species.
                
        With the observation that nodes in real world temporal networks may influence others, differential equations or difference equations seem appropriate for modelling the evolution of nodes as there is a rich body of literature exploring these methods use in modelling interacting variables. One of the issues that the differential equation method encounters is the prevalence of discrete jumps of edges forming and decaying.  
    
        Because of this we may consider exploring the possibility of using difference equations. We note however, that the progression of the network is generally continuous even if the events happen as discrete jumps. Because of this, we may wish to preserve the continuous temporal progression in our model.
        
        %This approach may overcome the problem of discrete observations, by defining a progression function that will only predict discrete formation or decay of edges\cite{hanneke2010discrete}. However, this imposes a significant limitation on the temporal granularity with which we can predict the state of the network. We would be limited to the granularity our data is collected at. This may be a problem if for example we had a series of weekly or monthly observations of networks we would not be able to predict interactions at each day. We can overcome both this limitation and the discrete jump limitation by using random dot product graphs. Interpolation may be possible in this case, but we would have no way of knowing if the interpolation had any basis in the real world.
        
        Looking at the work of Passino et al.\cite{sanna2021link}, the authors use random dot produce graphs\cite{athreya2017statistical} to approximate a temporal network as a matrix of probabilities of an edge existing between two nodes. In contrast to edges, these probabilities can evolve continuously, and so we can use differential equations to generate probabilistic networks at any temporal resolution we require. That is, we will be able to model the changes in the probabilities of edges continuous and from this, generate a network at any time step.

        Using the method in Passino et al.\cite{sanna2021link}, we can treat the sequence of embeddings as a dynamical system and then use differential equation modelling in a continuous space. That is, once we have found a latent space for each network. We know that each point in this space refers to a specific node in the network, and so, as the network changes, so too does the position of each of the points in the latent space. We then look to model this movement using differential equations. Our aim for this framework to be as general as possible and note that there may not yet be enough domain knowledge to perform traditional differential equation modelling to the desired accuracy. For example in network ecology models can be useful, but not perfect XXX cite XXX. Hence, we might wish to build on these models rather than trying to create something entirely new. This can be achieved by using this partial domain knowledge using it to create a universal differential equation (UDE) \cite{SciML_C_Rak}.

        \subsubsection{Theory}
            Developed by \Citeauthor{SciML_C_Rak}\cite{SciML_C_Rak}, Universal differential equation (UDEs) are a novel neural network architecture that aims to take the best of both traditional neural differential equation modelling and of flexible machine learning approaches to modelling. UDEs achieve this by combining some amount of domain knowledge in the form of a differential equation, with a neural network. This hybrid machine learning model is then trained on the observed data. Combining the two allows for most of the movement in the data to be captured by the differential equation, which contains the domain knowledge. In this way the neural network will only need to learn a theoretically simpler equation, given that a part of the system has already been captured. This then allows the neural network to be smaller, require fewer data, and be trained much faster than traditional neural network models. Given the flexibility of neural networks, the use of UDEs is natural when modelling a process that is not entirely understood\cite{kidger2022neural}. N
            
            There is an ecosystem of packages specifically designed for performing machine learning with UDEs. The ecosystem is called SciML or scientific machine learning\cite{SciML_C_Rak}. Largely, the SciML ecosystem has been optimised for flexibility and efficiency with respect to models available and training performance. Given there does not seem to be any other ecosystem with this feature, it seemed like 
            an obvious choice.
        
        \subsubsection{Applications}
            Whilst there has been much interest in implementing UDEs and neural ODEs, much of this work has been focussed on physics informed neural network and physics informed ordinary differential equations (PINNs and PINODEs) \cite{karniadakis2021physics,GAO2021110079,krishnapriyan2021characterizing,roehrl2020modeling}, and on improving modelling of fluids \cite{mahmoudabadbozchelou2021data,nguyen2022physics}. Alongside this, and given UDEs have gained popularity in the last few years, there have been a number of studies exploring their usefulness in modeling the effect of restrictions due to COVID-19 on the virus' spread \cite{Dandekar2020.04.03.20052084}. Although there has been a large amount of research into the usefulness of these types of models, to the best of this author's knowledge they have never been applied to the problem of predicting temporal networks. This seems to be a natural fit for UDEs and neural ODEs, given we may know relatively little about the processes that govern the evolution of temporal networks, and any information we do have can be incorporated into the model.

    \subsection{Symbolic Regression}
        Symbolic regression is a type of regression analysis that searches a space of equations to find an expression that matches data. This can be achieved in many ways and remains active area of research. One of the most popular algorithms is genetic programming\cite{schmidt2009distilling}. Genetic programming has been the subject of extensive research, and various improvements to speed and efficiency have been made XXX cite XXX. Genetic programming involves constructing a search tree using a genetic algorithm to yield a potential equation, which may match the data as well as numerically calculated partial derivatives of each of the input variables. Comparing with these derivatives is useful as it helps to ensure that the produced function equations have some grounding in the real world process that generated the data. The search tree is then pruned by comparing the partial derivatives of the candidate equation, with partial derivatives calculated from data. This process is then iterated many times to generate a suitable equation.

        The problem that symbolic regression aims to solve is to generate interpretable and ``meaningful'' equations from observed data. For example, both \cite{schmidt2009distilling,bongard2007automated} test their methods' capacity for obtaining a symbolic equation which physical simulation data, various pendula specifically. A ``meaningful'' equation in this case would be one that adheres to the laws of physics.


        Examples of methods include discovering equations governing the movement of simple harmonic and chaotic double pendula from data\cite{schmidt2009distilling}. In this paper the authors present an evolutionary algorithm to generate multiple candidate functions that approximate the partial derivatives of each variable that are calculated directly from the data. In [Cite rackaucas presentation], [<- authors] demonstrate that using symbolic regression, as opposed to just an NNDE, can improve the accuracy of extrapolating. One aspect of this improvement is having accurate numerical derivative to compare to. To ensure this, it is important that the data is sampled very frequently. This seems integral to the accuracy of the found equation. 
        
        Another approach to symbolic regression can be found in \cite{bongard2007automated}. This paper proposes a method to find a symbolic equation that approximates a learned numerical equation rather than directly from data. The candidate equation is then tested against the numerical equation in such a way that the difference between the two predictions are maximised. The algorithm will generate new initial conditions to find behaviour exhibited by the numerical equation, for example a fixed point, that is not exhibited by the functional equation. When a difference is found, the functional equation is adjusted to also exhibit the behaviour of the numerical equation. Especially when using a neural network model as the numerical equation, it seems these process may not be useful if the initial conditions are outside the scope of the training data.

        Having interpretable models that capture underlying relations is relevant to all fields of study, and so the applications of symbolic regression are incredibly varied. Various methods of symbolic regression have been use in manufacturing systems, chemical systems, and tumor research \cite{can2011comparison,keith2021combining,yoshihara2013inferring}. As well research into improvements is still on going.

        In very recent work, Kidger\cite{kidger2022neural}, demonstrates that, with NNDEs, two of the assumptions necessary for symbolic regression can be overcome. Those are the necessity for paired observations and derivatives, as well as the assumption that the function can be expressed as a shallow tree of symbolic operations. We are modelling a differential equation, and so will have access to the derivatives at any point. 
\end{section}
    \printbibliography
\end{document}