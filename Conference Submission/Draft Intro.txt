The modelling of temporal networks continues to be an important and unresolved problem in the field of network analysis. Discovering the underlying equations of these dynamical systems proves to be an even more challenging problem. This paper proposes a process with which we can find a set of equations that allow us to predict the how a temporal network will behave. Nodes within the network influence eachother and so we might wish to draw on the rich literature of differential equation modelling, which have been useful in modelling inumerable dynamical systems. Attempting to directly model the temporal adjacency matrix presents another challenge; changes in the network are discrete jumps, not smooth curves which can be nicely modelled by differential equations. We propose using random dot product graphs, which are well established in statistics, and singular value decomposition to resolve this issue. Creating a singular value decomposition of each of our network observations allows us to view the temporal network as a sample, from which we can model the dynamics of edge existence probabilities across time, now a continuous function. To regenerate the network from the embedding, we can simply multiply our embedding matrices together. This will give us a random dot product graph, where the entries (i,j) of the matrix will be the probability of an edge from i to j existing. In this form, the problem can be viewed as a dynamical system We believe this approach will be useful when applied to areas of medicine, especially protein interaction networks; population dynamics for network ecology; and social network modelling. 

By using this process, we also open the possibility of using the endlessly flexible toolbox of machine learning. In this paper we explore the usefulness of neural ODEs, a neural network that is trained to differential equation of temporal data, for discovering the governing function of a set of simple, synthetic temporal networks. This results in a black box DE, which is not very helpful for understanding our systems. To give more inight into what is really going on, we then use SINDy to find a linear combination of functions whose output is similar to that of the neural network. By doing this we may further understand the important factors that govern our temporal network.